{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-XY9sNjKSiOL"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ik_m85IV8RQA"
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xmdyl8EYRRUJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import Binarizer, KBinsDiscretizer\n",
    "from skopt import gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Integer\n",
    "from tqdm.notebook import tqdm\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SuVsTybzxhj0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_rf(X: np.ndarray, y: np.ndarray) -> RandomForestClassifier:\n",
    "    space = [\n",
    "        Real(0.000001, 0.01, 'log-uniform', name='ccp_alpha'),\n",
    "        Real(0.5, 0.85, 'uniform', name='max_features'),\n",
    "        Real(0.6, 0.95, 'uniform', name='max_samples'),\n",
    "        Integer(50, 1000, name='n_estimators')\n",
    "    ]\n",
    "    \n",
    "    @use_named_args(space)\n",
    "    def objective_f(ccp_alpha: float, max_features: float,\n",
    "                    max_samples: float, n_estimators: int) -> float:\n",
    "        test_cls = RandomForestClassifier(\n",
    "            min_samples_leaf=5, n_estimators=n_estimators,\n",
    "            random_state=42, verbose=True, n_jobs=-1,\n",
    "            ccp_alpha=ccp_alpha, oob_score=True, bootstrap=True,\n",
    "            max_samples=max_samples, max_features=max_features,\n",
    "        )\n",
    "        test_cls.fit(X, y)\n",
    "        nd = len(test_cls.oob_decision_function_.shape)\n",
    "        if nd != 2:\n",
    "            err_msg = f'`oob_decision_function_` is wrong! ' \\\n",
    "                      f'Expected 2-D array, got {nd}-D one!'\n",
    "            raise ValueError(err_msg)\n",
    "        filtered = list(\n",
    "            filter(\n",
    "                lambda idx: not any(np.isnan(\n",
    "                    test_cls.oob_decision_function_[idx]\n",
    "                )),\n",
    "                range(y.shape[0])\n",
    "            )\n",
    "        )\n",
    "        info_msg = f'OOB score is estimated using {len(filtered)} ' \\\n",
    "                   f'samples from {y.shape[0]}.'\n",
    "        print(info_msg)\n",
    "        if len(filtered) < 3:\n",
    "            err_msg = 'OOB score cannot be estimated!'\n",
    "            raise ValueError(err_msg)\n",
    "        quality = f1_score(\n",
    "            y_true=y[filtered],\n",
    "            y_pred=np.argmax(test_cls.oob_decision_function_[filtered],\n",
    "                             axis=-1),\n",
    "            average='macro'\n",
    "        )\n",
    "        return -quality\n",
    "    \n",
    "    res_gp = gp_minimize(\n",
    "        objective_f, space,\n",
    "        n_calls=32, n_random_starts=8,\n",
    "        n_restarts_optimizer=4, random_state=42,\n",
    "        verbose=True, n_jobs=1\n",
    "    )\n",
    "    best_parameters = {\n",
    "        'ccp_alpha': float(res_gp.x[0]),\n",
    "        'max_features': float(res_gp.x[1]),\n",
    "        'max_samples': float(res_gp.x[2]),\n",
    "        'n_estimators': int(res_gp.x[3]),\n",
    "    }\n",
    "    print(f'Best parameters are: {best_parameters}')\n",
    "    final_cls = RandomForestClassifier(\n",
    "        min_samples_leaf=5, random_state=42, verbose=True, n_jobs=-1,\n",
    "        oob_score=True, bootstrap=True,\n",
    "        ccp_alpha=best_parameters['ccp_alpha'],\n",
    "        n_estimators=best_parameters['n_estimators'],\n",
    "        max_samples=best_parameters['max_samples'],\n",
    "        max_features=best_parameters['max_features'],\n",
    "    )\n",
    "    final_cls.fit(X, y)\n",
    "    return final_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_latent_space_size(X: np.ndarray,\n",
    "                               figure_id: int=None) -> int:\n",
    "    normalizer = Pipeline(steps=[\n",
    "        (\n",
    "            'imputer',\n",
    "            SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        ),\n",
    "        (\n",
    "            'scaler',\n",
    "            StandardScaler(with_mean=True, with_std=True)\n",
    "        ),\n",
    "        (\n",
    "            'pca',\n",
    "            PCA(svd_solver='full', n_components=None)\n",
    "        )\n",
    "    ]).fit(X)\n",
    "    pca = normalizer.named_steps['pca']\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "    n = explained_variance_ratio.shape[0]\n",
    "    assert n == X.shape[1], f'{n} != {X.shape[1]}'\n",
    "    if n <= 2:\n",
    "        n_best_components = n\n",
    "    else:\n",
    "        n_best_components = 2\n",
    "        square = explained_variance_ratio[0] + explained_variance_ratio[1]\n",
    "        for idx in range(2, n - 1):\n",
    "            if square > 0.8:\n",
    "                break\n",
    "            n_best_components = idx + 1\n",
    "            square += explained_variance_ratio[idx]\n",
    "    if figure_id is not None:\n",
    "        plt.figure(figure_id, figsize=(7, 7))\n",
    "        plt.plot(list(range(1, n + 1)),\n",
    "                 explained_variance_ratio, 'b')\n",
    "        plt.plot([n_best_components, n_best_components],\n",
    "                 [0.0, np.max(explained_variance_ratio)], 'r')\n",
    "        plt.xlabel('Number of components')\n",
    "        plt.ylabel('Explained variance ratio')\n",
    "        plt.title('Percentage of variance explained by each of the components')\n",
    "        plt.show()\n",
    "    latent_space = 2\n",
    "    if n_best_components >= 4:\n",
    "        while latent_space < n_best_components:\n",
    "            latent_space *= 2\n",
    "        if latent_space > n_best_components:\n",
    "            latent_space //= 2\n",
    "    return latent_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8BZI96xER4Rj"
   },
   "outputs": [],
   "source": [
    "def build_normalizer(X: np.ndarray) -> Pipeline:\n",
    "    normalizer = Pipeline(steps=[\n",
    "        (\n",
    "            'imputer',\n",
    "            SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        ),\n",
    "        (\n",
    "            'scaler',\n",
    "            StandardScaler(with_mean=True, with_std=True)\n",
    "        ),\n",
    "        (\n",
    "            'pca',\n",
    "            PCA(random_state=42, whiten=True)\n",
    "        )\n",
    "    ])\n",
    "    return normalizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initializer():\n",
    "    try:\n",
    "        kernel_initializer = tf.keras.initializers.GlorotNormal(\n",
    "            seed=random.randint(0, 2147483647)\n",
    "        )\n",
    "    except:\n",
    "        kernel_initializer = tf.compat.v1.keras.initializers.glorot_normal(\n",
    "            seed=random.randint(0, 2147483647)\n",
    "        )\n",
    "    return kernel_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9yTdSjxYT6B1"
   },
   "outputs": [],
   "source": [
    "def build_neural_network(n_features: int, n_classes: int,\n",
    "                         n_latent: int, n_hidden: int, depth: int,\n",
    "                         nn_name: str) -> Tuple[tf.keras.Model, tf.keras.Model, \\\n",
    "                                                tf.keras.Model]:\n",
    "    if n_hidden < 1:\n",
    "        err_msg = f'The hidde layer size = {n_hidden} is too small!'\n",
    "    feature_vector = tf.keras.layers.Input(\n",
    "        shape=(n_features,), dtype=tf.float32,\n",
    "        name=f'{nn_name}_feature_vector'\n",
    "    )\n",
    "    block_input = feature_vector\n",
    "    for layer_idx in range(depth):\n",
    "        first_layer = tf.keras.layers.Dense(\n",
    "            units=n_hidden,\n",
    "            activation='tanh',\n",
    "            kernel_initializer=generate_initializer(),\n",
    "            bias_initializer='zeros',\n",
    "            name=f'{nn_name}_enc_dense{layer_idx * 3 + 1}'\n",
    "        )(block_input)\n",
    "        second_layer = tf.keras.layers.Dense(\n",
    "            units=n_hidden,\n",
    "            activation='tanh',\n",
    "            kernel_initializer=generate_initializer(),\n",
    "            bias_initializer='zeros',\n",
    "            name=f'{nn_name}_enc_dense{layer_idx * 3 + 2}'\n",
    "        )(first_layer)\n",
    "        third_layer = tf.keras.layers.Dense(\n",
    "            units=n_hidden,\n",
    "            activation='tanh',\n",
    "            kernel_initializer=generate_initializer(),\n",
    "            bias_initializer='zeros',\n",
    "            name=f'{nn_name}_enc_dense{layer_idx * 3 + 3}'\n",
    "        )(second_layer)\n",
    "        encoder_layer = tf.keras.layers.Add(\n",
    "            name=f'{nn_name}_enc_add{layer_idx + 1}'\n",
    "        )([first_layer, third_layer])\n",
    "        block_input = encoder_layer\n",
    "        del first_layer, second_layer, third_layer\n",
    "    del block_input\n",
    "    prior = tfp.distributions.Independent(\n",
    "        distribution=tfp.distributions.Normal(\n",
    "            loc=tf.zeros(n_latent),\n",
    "            scale=1\n",
    "        ),\n",
    "        reinterpreted_batch_ndims=1\n",
    "    )\n",
    "    latent_layer = tf.keras.layers.Dense(\n",
    "        units=tfp.layers.MultivariateNormalTriL.params_size(n_latent),\n",
    "        activation=None,\n",
    "        kernel_initializer=generate_initializer(),\n",
    "        bias_initializer='zeros',\n",
    "        name=f'{nn_name}_latent'\n",
    "    )(encoder_layer)\n",
    "    z = tfp.layers.MultivariateNormalTriL(\n",
    "        event_size=n_latent,\n",
    "        activity_regularizer=tfp.layers.KLDivergenceRegularizer(\n",
    "            distribution_b=prior,\n",
    "            weight=1e-3\n",
    "        ),\n",
    "        name=f'{nn_name}_z'\n",
    "    )(latent_layer)\n",
    "    classifier_input = tf.keras.layers.Input(\n",
    "        shape=(n_latent,), dtype=tf.float32,\n",
    "        name=f'{nn_name}_feature_vector'\n",
    "    )\n",
    "    hidden_layer = tf.keras.layers.Dense(\n",
    "        units=n_hidden,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=generate_initializer(),\n",
    "        bias_initializer='zeros',\n",
    "        name=f'{nn_name}_cls_hidden'\n",
    "    )(classifier_input)\n",
    "    cls_layer = tf.keras.layers.Dense(\n",
    "        units=n_classes,\n",
    "        activation='softmax',\n",
    "        kernel_initializer=generate_initializer(),\n",
    "        bias_initializer='zeros',\n",
    "        name=f'{nn_name}_cls_output'\n",
    "    )(hidden_layer)\n",
    "    cls_name = f'{nn_name}_cls'\n",
    "    cls_model = tf.keras.Model(\n",
    "        inputs=classifier_input,\n",
    "        outputs=cls_layer,\n",
    "        name=cls_name\n",
    "    )\n",
    "    cls_model.build(input_shape=[None, n_latent])\n",
    "    block_input = z\n",
    "    for layer_idx in range(depth):\n",
    "        first_layer = tf.keras.layers.Dense(\n",
    "            units=n_hidden,\n",
    "            activation='tanh',\n",
    "            kernel_initializer=generate_initializer(),\n",
    "            bias_initializer='zeros',\n",
    "            name=f'{nn_name}_dec_dense{layer_idx * 3 + 1}'\n",
    "        )(block_input)\n",
    "        second_layer = tf.keras.layers.Dense(\n",
    "            units=n_hidden,\n",
    "            activation='tanh',\n",
    "            kernel_initializer=generate_initializer(),\n",
    "            bias_initializer='zeros',\n",
    "            name=f'{nn_name}_dec_dense{layer_idx * 3 + 2}'\n",
    "        )(first_layer)\n",
    "        third_layer = tf.keras.layers.Dense(\n",
    "            units=n_hidden,\n",
    "            activation='tanh',\n",
    "            kernel_initializer=generate_initializer(),\n",
    "            bias_initializer='zeros',\n",
    "            name=f'{nn_name}_dec_dense{layer_idx * 3 + 3}'\n",
    "        )(second_layer)\n",
    "        decoder_layer = tf.keras.layers.Add(\n",
    "            name=f'{nn_name}_dec_add{layer_idx + 1}'\n",
    "        )([first_layer, third_layer])\n",
    "        block_input = decoder_layer\n",
    "        del first_layer, second_layer, third_layer\n",
    "    reconstruction_name =   f'{nn_name}_reconstruction'\n",
    "    reconstruction_layer = tf.keras.layers.Dense(\n",
    "        units=n_features,\n",
    "        activation=None,\n",
    "        kernel_initializer=generate_initializer(),\n",
    "        bias_initializer='zeros',\n",
    "        name=reconstruction_name\n",
    "    )(decoder_layer)\n",
    "    encoder_model = tf.keras.Model(\n",
    "        inputs=feature_vector,\n",
    "        outputs=z,\n",
    "        name=f'{nn_name}_enc'\n",
    "    )\n",
    "    united_model = tf.keras.Model(\n",
    "        inputs=feature_vector,\n",
    "        outputs=[cls_model(z), reconstruction_layer],\n",
    "        name=f'{nn_name}_vae'\n",
    "    )\n",
    "    encoder_model.build(input_shape=[None, n_features])\n",
    "    metrics = {cls_name: [tf.keras.metrics.CategoricalAccuracy()]}\n",
    "    losses = {\n",
    "        cls_name: tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        reconstruction_name: tf.keras.losses.LogCosh()\n",
    "    }\n",
    "    loss_weights = {\n",
    "        cls_name: 1.0,\n",
    "        reconstruction_name: 1.5\n",
    "    }\n",
    "    radam = tfa.optimizers.RectifiedAdam(learning_rate=1e-3)\n",
    "    ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "    united_model.compile(optimizer=ranger, loss=losses,\n",
    "                         loss_weights=loss_weights, metrics=metrics)\n",
    "    return united_model, encoder_model, cls_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_inputs(X: np.ndarray, vae: tf.keras.Model,\n",
    "                       batch_size: int) -> np.ndarray:\n",
    "    res = vae.predict(X, batch_size=batch_size)\n",
    "    if not isinstance(res, list):\n",
    "        err_msg = f'The result is wrong! Expected a 2-D list, ' \\\n",
    "                  f'got {type(res)}.'\n",
    "        raise ValueError(err_msg)\n",
    "    if len(res) != 2:\n",
    "        err_msg = f'The result is wrong! Expected a 2-D list, ' \\\n",
    "                  f'got {len(res)}-D one.'\n",
    "        raise ValueError(err_msg)\n",
    "    if not isinstance(res[1], np.ndarray):\n",
    "        err_msg = f'The second item of the result is wrong! ' \\\n",
    "                  f'Expected {type(np.array([1, 2]))}, got {type(res[1])}.'\n",
    "        raise ValueError(err_msg)\n",
    "    if res[1].shape != X.shape:\n",
    "        err_msg = f'The result shape is wrong! Expected {X.shape}, ' \\\n",
    "                  f'got {res[1].shape}.'\n",
    "        raise ValueError(err_msg)\n",
    "    return res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "T9Vd3cA0pCX7"
   },
   "outputs": [],
   "source": [
    "def calculate_projections(X: np.ndarray, encoder: tf.keras.Model,\n",
    "                          n_samples: int, batch_size: int) -> List[np.ndarray]:\n",
    "    assert n_samples > 0\n",
    "    n_batches = int(np.ceil(X.shape[0] / float(batch_size)))\n",
    "    projections = [[] for _ in range(n_samples)]\n",
    "    for batch_idx in tqdm(list(range(n_batches))):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = min(X.shape[0], batch_start + batch_size)\n",
    "        distr = encoder(X[batch_start:batch_end])\n",
    "        assert isinstance(distr, tfp.distributions.Distribution)\n",
    "        if n_samples > 1:\n",
    "            y_inst = distr.sample()\n",
    "            if not isinstance(y_inst, np.ndarray):\n",
    "                y_inst = y_inst.numpy()\n",
    "            assert len(y_inst.shape) == 2\n",
    "            projections[0].append(y_inst)\n",
    "            del y_inst\n",
    "            for prj_idx in range(1, n_samples):\n",
    "                y_inst = distr.sample()\n",
    "                if not isinstance(y_inst, np.ndarray):\n",
    "                    y_inst = y_inst.numpy()\n",
    "                assert len(y_inst.shape) == 2\n",
    "                projections[prj_idx].append(y_inst)\n",
    "                del y_inst\n",
    "        else:\n",
    "            y_inst = distr.mean()\n",
    "            if not isinstance(y_inst, np.ndarray):\n",
    "                y_inst = y_inst.numpy()\n",
    "            assert len(y_inst.shape) == 2\n",
    "            projections[0].append(y_inst)\n",
    "            del y_inst\n",
    "        del distr\n",
    "    return [np.vstack(cur) for cur in projections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions_of_data(features: np.ndarray) -> np.ndarray:\n",
    "    if features.shape[1] < 12:\n",
    "        n_components = features.shape[1]\n",
    "    else:\n",
    "        n_components = max(12, features.shape[1] // 3)\n",
    "    preprocessed_features = Pipeline(\n",
    "        steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('pca', PCA(n_components=n_components, random_state=42))\n",
    "        ]\n",
    "    ).fit_transform(features)\n",
    "    print('Features are preprocessed.')\n",
    "    reduced_features = umap.UMAP(\n",
    "        low_memory=False,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=True\n",
    "    ).fit_transform(preprocessed_features)\n",
    "    print('Feature space is reduced.')\n",
    "    del preprocessed_features\n",
    "    return reduced_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Pght_Ba0oy52"
   },
   "outputs": [],
   "source": [
    "def predict_proba(X: np.ndarray, encoder: tf.keras.Model, classifier: tf.keras.Model,\n",
    "                  n_samples: int, batch_size: int) -> np.ndarray:\n",
    "    projections = calculate_projections(X, encoder, n_samples, batch_size)\n",
    "    y = classifier.predict(projections[0], batch_size=batch_size)\n",
    "    assert len(y.shape) == 2\n",
    "    if n_samples > 1:\n",
    "        for prj_idx in range(1, n_samples):\n",
    "            y += classifier.predict(projections[prj_idx], batch_size=batch_size)\n",
    "    proba = y.astype(np.float64) / float(n_samples)\n",
    "    return proba / np.sum(proba, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QbRSZHmWtj_t"
   },
   "outputs": [],
   "source": [
    "class TrainsetGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x: np.ndarray, y: np.ndarray, n_classes: int, batch_size: int):\n",
    "        self.x, self.y = x, y\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.indices_ = np.array(list(range(self.x.shape[0])), dtype=np.int32)\n",
    "        self.class_distr_ = dict()\n",
    "        for sample_idx, class_idx in enumerate(y.tolist()):\n",
    "            if class_idx in self.class_distr_:\n",
    "                self.class_distr_[class_idx].append(sample_idx)\n",
    "            else:\n",
    "                self.class_distr_[class_idx] = [sample_idx]\n",
    "        for class_idx in self.class_distr_:\n",
    "            self.class_distr_[class_idx] = np.array(self.class_distr_[class_idx],\n",
    "                                                    dtype=np.int32)\n",
    "        assert len(self.x.shape) == 2\n",
    "        assert self.x.shape[0] > self.batch_size\n",
    "        assert len(self.y.shape) == 1\n",
    "        assert self.y.shape[0] == self.x.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.x.shape[0] / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, batch_idx: int):\n",
    "        batch_indices = []\n",
    "        selected_classes = sorted(list(self.class_distr_.keys()))\n",
    "        if self.batch_size < len(selected_classes):\n",
    "            selected_classes = random.sample(selected_classes, self.batch_size)\n",
    "        for counter, class_idx in enumerate(selected_classes):\n",
    "            n = int(round(\n",
    "                (self.batch_size - len(batch_indices)) / \n",
    "                (len(selected_classes) - counter)\n",
    "            ))\n",
    "            batch_indices += np.random.choice(\n",
    "                a=self.class_distr_[class_idx],\n",
    "                size=n\n",
    "            ).tolist()\n",
    "        X_batch = np.empty((len(batch_indices), self.x.shape[1]), dtype=np.float32)\n",
    "        y_batch = [\n",
    "            np.zeros((len(batch_indices), self.n_classes), dtype=np.float32),\n",
    "        ]\n",
    "        for idx, sample_idx in enumerate(batch_indices):\n",
    "            X_batch[idx] = self.x[sample_idx]\n",
    "            class_idx = self.y[sample_idx]\n",
    "            y_batch[0][idx, class_idx] = 1.0\n",
    "        y_batch.append(X_batch)\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ct0xUl_IwHgF"
   },
   "outputs": [],
   "source": [
    "class ValidsetGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x: np.ndarray, y: np.ndarray, n_classes: int, batch_size: int):\n",
    "        self.x, self.y = x, y\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        assert len(self.x.shape) == 2\n",
    "        assert self.x.shape[0] > self.batch_size\n",
    "        assert len(self.y.shape) == 1\n",
    "        assert self.y.shape[0] == self.x.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.x.shape[0] / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, batch_idx: int):\n",
    "        batch_start = batch_idx * self.batch_size\n",
    "        batch_end = min(batch_start + self.batch_size, self.x.shape[0])\n",
    "        batch_indices = list(range(batch_start, batch_end))\n",
    "        X_batch = np.empty((len(batch_indices), self.x.shape[1]), dtype=np.float32)\n",
    "        y_batch = [\n",
    "            np.zeros((len(batch_indices), self.n_classes), dtype=np.float32),\n",
    "        ]\n",
    "        for idx, sample_idx in enumerate(batch_indices):\n",
    "            X_batch[idx] = self.x[sample_idx]\n",
    "            class_idx = self.y[sample_idx]\n",
    "            y_batch[0][idx, class_idx] = 1.0\n",
    "        y_batch.append(X_batch)\n",
    "        return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XySEOAZv6PA3"
   },
   "outputs": [],
   "source": [
    "def show_training_process(history: tf.keras.callbacks.History, metric_name: str,\n",
    "                          figure_id: int=1, comment: str=''):\n",
    "    val_metric_name = 'val_' + metric_name\n",
    "    if metric_name not in history.history:\n",
    "        err_msg = f'The metric \"{metric_name}\" is not found! Available metrics are: ' \\\n",
    "                  f'{list(history.history.keys())}.'\n",
    "        raise ValueError(err_msg)\n",
    "    plt.figure(figure_id, figsize=(5, 5))\n",
    "    interesting_metric = history.history[metric_name]\n",
    "    plt.plot(list(range(len(interesting_metric))), interesting_metric,\n",
    "             label=f'Training {metric_name}')\n",
    "    if val_metric_name in history.history:\n",
    "        interesting_val_metric = history.history[val_metric_name]\n",
    "        assert len(interesting_metric) == len(interesting_val_metric)\n",
    "        plt.plot(list(range(len(interesting_val_metric))),\n",
    "                 interesting_val_metric,\n",
    "                 label=f'Validation {metric_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(metric_name)\n",
    "    if len(comment) > 0:\n",
    "        plt.title(f'Training process of {comment}')\n",
    "    else:\n",
    "        plt.title('Training process')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classes(features: np.ndarray, targets: np.ndarray, class_colors: List[str],\n",
    "                 title: str='', figure_id: int=0):\n",
    "    if features.shape[0] != targets.shape[0]:\n",
    "        err_msg = f'Features do not correspond to targets! ' \\\n",
    "                  f'{features.shape[0]} != {targets.shape[0]}'\n",
    "        raise ValueError(err_msg)\n",
    "    if len(features.shape) != 2:\n",
    "        err_msg = f'Features are wrong! Expected 2-D array, got ' \\\n",
    "                  f'{len(features.shape)}-D one.'\n",
    "        raise ValueError(err_msg)\n",
    "    if features.shape[1] != 2:\n",
    "        err_msg = f'Features are wrong! Expected number of ' \\\n",
    "                  f'columns is 2, got {features.shape[1]}.'\n",
    "        raise ValueError(err_msg)\n",
    "    if len(targets.shape) != 1:\n",
    "        err_msg = f'Targets are wrong! Expected 1-D array, got ' \\\n",
    "                  f'{len(targets.shape)}-D one.'\n",
    "        raise ValueError(err_msg)\n",
    "    set_of_classes = set(targets.tolist())\n",
    "    n_classes = len(class_colors)\n",
    "    if set_of_classes != set(range(n_classes)):\n",
    "        err_msg = ''\n",
    "        raise ValueError(err_msg)\n",
    "    class_colors = [class_colors[class_label] for class_label in targets]\n",
    "    fig = plt.figure(figure_id, figsize=(11, 11))\n",
    "    plt.scatter(x=features[:, 0], y=features[:, 1], marker='o', c=class_colors)\n",
    "    if len(title) > 0:\n",
    "        plt.title(f'UMAP projections of {title} ({n_classes} classes)')\n",
    "    else:\n",
    "        plt.title(f'UMAP projections of inputs ({n_classes} classes)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3-HMveIH1kGs"
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sFy1uxbg33tm"
   },
   "outputs": [],
   "source": [
    "MINIBATCH_SIZE_FOR_TRAINING = 1024\n",
    "MINIBATCH_SIZE_FOR_INFERENCE = 64\n",
    "MAX_TRAINING_EPOCHS = 2000\n",
    "ES_PATIENCE = 50\n",
    "HIDDEN_LAYER_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "Bj8e6qC11X2d",
    "outputId": "c02f6d0d-10f8-40cd-b711-8e007493b13f"
   },
   "outputs": [],
   "source": [
    "dataset = fetch_covtype(return_X_y=False, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2yHzxi3_AVrP"
   },
   "outputs": [],
   "source": [
    "classes_dict = dict()\n",
    "for val in dataset.target.tolist():\n",
    "    if val not in classes_dict:\n",
    "        classes_dict[val] = len(classes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Wd2kWW202JXe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (581012, 54)\n",
      "y.shape = (581012,)\n",
      "Number of classes is 7.\n"
     ]
    }
   ],
   "source": [
    "print(f'X.shape = {dataset.data.shape}')\n",
    "print(f'y.shape = {dataset.target.shape}')\n",
    "print(f'Number of classes is {len(classes_dict)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_OF_CLASSES = ['b', 'g', 'r', 'c', 'm', 'y', 'k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_zquwHNA2TNm"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.data,\n",
    "    np.array([classes_dict[val] for val in dataset.target.tolist()], dtype=np.int32),\n",
    "    test_size=0.05, stratify=dataset.target, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CGNgEIwD26fc"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.05, stratify=y_train, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "e9k-dk272i3F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (524362, 54)\n",
      "y_train.shape = (524362,)\n",
      "Number of classes is 7.\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "number_of_classes_for_training = len(set(map(lambda it: int(it), y_train.tolist())))\n",
    "print(f'Number of classes is {number_of_classes_for_training}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ueqb35hi2zJ0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid.shape = (27599, 54)\n",
      "y_valid.shape = (27599,)\n",
      "Number of classes is 7.\n"
     ]
    }
   ],
   "source": [
    "print(f'X_valid.shape = {X_valid.shape}')\n",
    "print(f'y_valid.shape = {y_valid.shape}')\n",
    "number_of_classes_for_validation = len(set(map(lambda it: int(it), y_valid.tolist())))\n",
    "print(f'Number of classes is {number_of_classes_for_validation}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Qxq0visG2uqA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape = (29051, 54)\n",
      "y_test.shape = (29051,)\n",
      "Number of classes is 7.\n"
     ]
    }
   ],
   "source": [
    "print(f'X_test.shape = {X_test.shape}')\n",
    "print(f'y_test.shape = {y_test.shape}')\n",
    "number_of_classes_for_testing = len(set(map(lambda it: int(it), y_test.tolist())))\n",
    "print(f'Number of classes is {number_of_classes_for_testing}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent_space_size = estimate_latent_space_size(X_train, figure_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent space is 32.\n"
     ]
    }
   ],
   "source": [
    "print(f'Latent space is {latent_space_size}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_RF_PARAMS = {'ccp_alpha': 1e-06, 'max_features': 0.8,\n",
    "                  'max_samples': 0.9, 'n_estimators': 500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "TlZalyDU6n2Z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 18.3min finished\n"
     ]
    }
   ],
   "source": [
    "if BEST_RF_PARAMS is None:\n",
    "    baseline = find_best_rf(X_train, y_train)\n",
    "else:\n",
    "    baseline = RandomForestClassifier(\n",
    "        random_state=42, verbose=True, n_jobs=-1,\n",
    "        oob_score=True, bootstrap=True,\n",
    "        ccp_alpha=BEST_RF_PARAMS['ccp_alpha'],\n",
    "        n_estimators=BEST_RF_PARAMS['n_estimators'],\n",
    "        max_samples=BEST_RF_PARAMS['max_samples'],\n",
    "        max_features=BEST_RF_PARAMS['max_features']\n",
    "    ).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal tree depth is 37.\n",
      "Maximal tree depth is 50.\n",
      "Median tree depth is 42.\n",
      "95% tree depth is 46.\n",
      "Mean tree depth is 41.754.\n"
     ]
    }
   ],
   "source": [
    "tree_depths = [cur_tree.get_depth() for cur_tree in baseline.estimators_]\n",
    "tree_depths.sort()\n",
    "print(f'Minimal tree depth is {tree_depths[0]}.')\n",
    "print(f'Maximal tree depth is {tree_depths[-1]}.')\n",
    "print(f'Median tree depth is {tree_depths[len(tree_depths) // 2]}.')\n",
    "print(f'95% tree depth is {tree_depths[int(0.95 * (len(tree_depths) - 1))]}.')\n",
    "print(f'Mean tree depth is {np.mean(tree_depths)}.')\n",
    "encoder_depth = max(1, tree_depths[int(0.95 * (len(tree_depths) - 1))] // 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DewcTZgA7BVB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9755    0.9675    0.9715     10063\n",
      "           1     0.9720    0.9807    0.9763     13457\n",
      "           2     0.9600    0.9747    0.9673      1698\n",
      "           3     0.9308    0.8647    0.8966       451\n",
      "           4     0.9530    0.9345    0.9437       825\n",
      "           5     0.9782    0.9671    0.9726       974\n",
      "           6     0.9286    0.8931    0.9105       131\n",
      "\n",
      "    accuracy                         0.9713     27599\n",
      "   macro avg     0.9569    0.9403    0.9484     27599\n",
      "weighted avg     0.9713    0.9713    0.9713     27599\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_valid, y_pred=baseline.predict(X_valid),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "S_86kMn57JFg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9765    0.9675    0.9720     10592\n",
      "           1     0.9717    0.9824    0.9770     14165\n",
      "           2     0.9656    0.9737    0.9696      1788\n",
      "           3     0.9624    0.8632    0.9101       475\n",
      "           4     0.9459    0.9459    0.9459       868\n",
      "           5     0.9762    0.9581    0.9670      1026\n",
      "           6     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.9720     29051\n",
      "   macro avg     0.9580    0.9360    0.9465     29051\n",
      "weighted avg     0.9720    0.9720    0.9719     29051\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=baseline.predict(X_test),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OZj5Rksa3UrG"
   },
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "2gWkVba73itc"
   },
   "outputs": [],
   "source": [
    "input_normalizer = build_normalizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "9exQnTea3n8m"
   },
   "outputs": [],
   "source": [
    "X_train = input_normalizer.transform(X_train)\n",
    "X_valid = input_normalizer.transform(X_valid)\n",
    "X_test = input_normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "nhzatua536gO"
   },
   "outputs": [],
   "source": [
    "trainset_gen = TrainsetGenerator(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    n_classes=len(classes_dict),\n",
    "    batch_size=MINIBATCH_SIZE_FOR_TRAINING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "CrZ5546EAESh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.6481367e-01 -7.2752440e-01 -6.3458222e-01 -7.2056454e-01\n",
      "  4.7534648e-01 -9.5588958e-01 -1.3696417e-01  2.2365841e-01\n",
      " -7.4220991e-01  1.8210919e+00 -1.2941617e+00  1.6701691e+00\n",
      " -1.4383140e+00  2.3334509e-01  2.5504935e-01 -7.6389384e-01\n",
      "  2.8694868e-01 -4.9366906e-01 -7.4199474e-01 -4.3707731e-01\n",
      "  1.3714510e-01 -5.5590701e-01 -1.6601421e-01 -1.1571726e-01\n",
      "  1.7112322e-01  6.8379506e-02 -5.7876389e-02 -1.5353777e-01\n",
      "  2.3908406e-02 -7.5148620e-02 -1.4304197e-02 -5.1669176e-03\n",
      " -1.1302061e-02  4.6780957e-03 -3.4525152e-02 -4.7401305e-02\n",
      " -1.7942935e-02  2.9622302e-03 -1.6188257e-03  1.6566034e-01\n",
      "  1.3197633e+00 -2.2789581e-01  8.7245440e-01 -2.1616685e-01\n",
      " -8.9910114e-01 -1.8598354e+00 -1.6068684e-01 -9.7984111e-01\n",
      "  2.0779929e+00  1.1571113e+00  2.1292517e+00  2.2986341e-02\n",
      " -1.4899393e+00 -2.0786524e+00]\n",
      "[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.16481366753578186, -0.7275243997573853, -0.6345822215080261, -0.7205645442008972, 0.47534647583961487, -0.9558895826339722, -0.13696417212486267, 0.22365841269493103, -0.7422099113464355, 1.821091890335083, -1.2941616773605347, 1.6701691150665283, -1.4383139610290527, 0.23334509134292603, 0.25504934787750244, -0.7638938426971436, 0.28694868087768555, -0.4936690628528595, -0.7419947385787964, -0.4370773136615753, 0.13714510202407837, -0.5559070110321045, -0.16601420938968658, -0.11571726202964783, 0.1711232215166092, 0.06837950646877289, -0.05787638947367668, -0.15353776514530182, 0.023908406496047974, -0.07514861971139908, -0.014304197393357754, -0.005166917573660612, -0.011302061378955841, 0.004678095690906048, -0.034525152295827866, -0.0474013052880764, -0.01794293522834778, 0.0029622302390635014, -0.0016188257141038775, 0.1656603366136551, 1.3197633028030396, -0.2278958112001419, 0.8724544048309326, -0.21616685390472412, -0.8991011381149292, -1.8598353862762451, -0.16068683564662933, -0.9798411130905151, 2.0779929161071777, 1.1571112871170044, 2.129251718521118, 0.022986341267824173, -1.4899393320083618, -2.0786523818969727]\n"
     ]
    }
   ],
   "source": [
    "X_, y_ = trainset_gen[0]\n",
    "print(X_[0])\n",
    "for it in y_:\n",
    "    print(it[0].tolist() if isinstance(it[0], np.ndarray) else it[0])\n",
    "del X_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "J6E4MUgKLnTz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 frequency is 14%.\n",
      "Class 1 frequency is 14%.\n",
      "Class 2 frequency is 14%.\n",
      "Class 3 frequency is 14%.\n",
      "Class 4 frequency is 14%.\n",
      "Class 5 frequency is 14%.\n",
      "Class 6 frequency is 14%.\n"
     ]
    }
   ],
   "source": [
    "train_class_freq = dict()\n",
    "for idx1 in range(len(trainset_gen)):\n",
    "    X_, y_ = trainset_gen[idx1]\n",
    "    for idx2 in range(X_.shape[0]):\n",
    "        class_idx1 = int(np.argmax(y_[0][idx2]))\n",
    "        if class_idx1 in train_class_freq:\n",
    "            train_class_freq[class_idx1] += 1\n",
    "        else:\n",
    "            train_class_freq[class_idx1] = 1\n",
    "    del X_, y_\n",
    "sum_freq = 0\n",
    "for class_idx1 in sorted(train_class_freq.keys()):\n",
    "    sum_freq += train_class_freq[class_idx1]\n",
    "for class_idx1 in sorted(train_class_freq.keys()):\n",
    "    percent = 100.0 * train_class_freq[class_idx1]\n",
    "    percent /= float(sum_freq)\n",
    "    print(f'Class {class_idx1} frequency is {int(round(percent))}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "5F8l7axU4TY-"
   },
   "outputs": [],
   "source": [
    "validset_gen = ValidsetGenerator(\n",
    "    x=X_valid,\n",
    "    y=y_valid,\n",
    "    n_classes=len(classes_dict),\n",
    "    batch_size=MINIBATCH_SIZE_FOR_TRAINING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "SunvCCo5AHDF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 frequency is 36%.\n",
      "Class 1 frequency is 49%.\n",
      "Class 2 frequency is 6%.\n",
      "Class 3 frequency is 2%.\n",
      "Class 4 frequency is 3%.\n",
      "Class 5 frequency is 4%.\n",
      "Class 6 frequency is 0%.\n"
     ]
    }
   ],
   "source": [
    "val_class_freq = dict()\n",
    "for idx1 in range(len(validset_gen)):\n",
    "    X_, y_ = validset_gen[idx1]\n",
    "    for idx2 in range(X_.shape[0]):\n",
    "        class_idx1 = int(np.argmax(y_[0][idx2]))\n",
    "        if class_idx1 in val_class_freq:\n",
    "            val_class_freq[class_idx1] += 1\n",
    "        else:\n",
    "            val_class_freq[class_idx1] = 1\n",
    "    del X_, y_\n",
    "sum_freq = 0\n",
    "for class_idx1 in sorted(val_class_freq.keys()):\n",
    "    sum_freq += val_class_freq[class_idx1]\n",
    "for class_idx1 in sorted(val_class_freq.keys()):\n",
    "    percent = 100.0 * val_class_freq[class_idx1]\n",
    "    percent /= float(sum_freq)\n",
    "    print(f'Class {class_idx1} frequency is {int(round(percent))}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "gD_V0PjA4Wuc"
   },
   "outputs": [],
   "source": [
    "trainable_nn, encoding_nn, classification_nn = build_neural_network(\n",
    "    n_features=X_valid.shape[1], n_classes=len(classes_dict), depth=encoder_depth,\n",
    "    n_latent=latent_space_size, n_hidden=HIDDEN_LAYER_SIZE, nn_name='covertype'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mvAJp-FXBOkH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"covertype_vae\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "covertype_feature_vector (Input [(None, 54)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense1 (Dense)    (None, 512)          28160       covertype_feature_vector[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense2 (Dense)    (None, 512)          262656      covertype_enc_dense1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense3 (Dense)    (None, 512)          262656      covertype_enc_dense2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add1 (Add)        (None, 512)          0           covertype_enc_dense1[0][0]       \n",
      "                                                                 covertype_enc_dense3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense4 (Dense)    (None, 512)          262656      covertype_enc_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense5 (Dense)    (None, 512)          262656      covertype_enc_dense4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense6 (Dense)    (None, 512)          262656      covertype_enc_dense5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add2 (Add)        (None, 512)          0           covertype_enc_dense4[0][0]       \n",
      "                                                                 covertype_enc_dense6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense7 (Dense)    (None, 512)          262656      covertype_enc_add2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense8 (Dense)    (None, 512)          262656      covertype_enc_dense7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense9 (Dense)    (None, 512)          262656      covertype_enc_dense8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add3 (Add)        (None, 512)          0           covertype_enc_dense7[0][0]       \n",
      "                                                                 covertype_enc_dense9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense10 (Dense)   (None, 512)          262656      covertype_enc_add3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense11 (Dense)   (None, 512)          262656      covertype_enc_dense10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense12 (Dense)   (None, 512)          262656      covertype_enc_dense11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add4 (Add)        (None, 512)          0           covertype_enc_dense10[0][0]      \n",
      "                                                                 covertype_enc_dense12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense13 (Dense)   (None, 512)          262656      covertype_enc_add4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense14 (Dense)   (None, 512)          262656      covertype_enc_dense13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense15 (Dense)   (None, 512)          262656      covertype_enc_dense14[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add5 (Add)        (None, 512)          0           covertype_enc_dense13[0][0]      \n",
      "                                                                 covertype_enc_dense15[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense16 (Dense)   (None, 512)          262656      covertype_enc_add5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense17 (Dense)   (None, 512)          262656      covertype_enc_dense16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense18 (Dense)   (None, 512)          262656      covertype_enc_dense17[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add6 (Add)        (None, 512)          0           covertype_enc_dense16[0][0]      \n",
      "                                                                 covertype_enc_dense18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense19 (Dense)   (None, 512)          262656      covertype_enc_add6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense20 (Dense)   (None, 512)          262656      covertype_enc_dense19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense21 (Dense)   (None, 512)          262656      covertype_enc_dense20[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add7 (Add)        (None, 512)          0           covertype_enc_dense19[0][0]      \n",
      "                                                                 covertype_enc_dense21[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense22 (Dense)   (None, 512)          262656      covertype_enc_add7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense23 (Dense)   (None, 512)          262656      covertype_enc_dense22[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense24 (Dense)   (None, 512)          262656      covertype_enc_dense23[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add8 (Add)        (None, 512)          0           covertype_enc_dense22[0][0]      \n",
      "                                                                 covertype_enc_dense24[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense25 (Dense)   (None, 512)          262656      covertype_enc_add8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense26 (Dense)   (None, 512)          262656      covertype_enc_dense25[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense27 (Dense)   (None, 512)          262656      covertype_enc_dense26[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add9 (Add)        (None, 512)          0           covertype_enc_dense25[0][0]      \n",
      "                                                                 covertype_enc_dense27[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense28 (Dense)   (None, 512)          262656      covertype_enc_add9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense29 (Dense)   (None, 512)          262656      covertype_enc_dense28[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense30 (Dense)   (None, 512)          262656      covertype_enc_dense29[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add10 (Add)       (None, 512)          0           covertype_enc_dense28[0][0]      \n",
      "                                                                 covertype_enc_dense30[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense31 (Dense)   (None, 512)          262656      covertype_enc_add10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense32 (Dense)   (None, 512)          262656      covertype_enc_dense31[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense33 (Dense)   (None, 512)          262656      covertype_enc_dense32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add11 (Add)       (None, 512)          0           covertype_enc_dense31[0][0]      \n",
      "                                                                 covertype_enc_dense33[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense34 (Dense)   (None, 512)          262656      covertype_enc_add11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense35 (Dense)   (None, 512)          262656      covertype_enc_dense34[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense36 (Dense)   (None, 512)          262656      covertype_enc_dense35[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add12 (Add)       (None, 512)          0           covertype_enc_dense34[0][0]      \n",
      "                                                                 covertype_enc_dense36[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense37 (Dense)   (None, 512)          262656      covertype_enc_add12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense38 (Dense)   (None, 512)          262656      covertype_enc_dense37[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense39 (Dense)   (None, 512)          262656      covertype_enc_dense38[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add13 (Add)       (None, 512)          0           covertype_enc_dense37[0][0]      \n",
      "                                                                 covertype_enc_dense39[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense40 (Dense)   (None, 512)          262656      covertype_enc_add13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense41 (Dense)   (None, 512)          262656      covertype_enc_dense40[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense42 (Dense)   (None, 512)          262656      covertype_enc_dense41[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add14 (Add)       (None, 512)          0           covertype_enc_dense40[0][0]      \n",
      "                                                                 covertype_enc_dense42[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense43 (Dense)   (None, 512)          262656      covertype_enc_add14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense44 (Dense)   (None, 512)          262656      covertype_enc_dense43[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_dense45 (Dense)   (None, 512)          262656      covertype_enc_dense44[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_enc_add15 (Add)       (None, 512)          0           covertype_enc_dense43[0][0]      \n",
      "                                                                 covertype_enc_dense45[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_latent (Dense)        (None, 560)          287280      covertype_enc_add15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_z (MultivariateNormal multiple             0           covertype_latent[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense1 (Dense)    (None, 512)          16896       covertype_z[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense2 (Dense)    (None, 512)          262656      covertype_dec_dense1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense3 (Dense)    (None, 512)          262656      covertype_dec_dense2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add1 (Add)        (None, 512)          0           covertype_dec_dense1[0][0]       \n",
      "                                                                 covertype_dec_dense3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense4 (Dense)    (None, 512)          262656      covertype_dec_add1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense5 (Dense)    (None, 512)          262656      covertype_dec_dense4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense6 (Dense)    (None, 512)          262656      covertype_dec_dense5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add2 (Add)        (None, 512)          0           covertype_dec_dense4[0][0]       \n",
      "                                                                 covertype_dec_dense6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense7 (Dense)    (None, 512)          262656      covertype_dec_add2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense8 (Dense)    (None, 512)          262656      covertype_dec_dense7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense9 (Dense)    (None, 512)          262656      covertype_dec_dense8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add3 (Add)        (None, 512)          0           covertype_dec_dense7[0][0]       \n",
      "                                                                 covertype_dec_dense9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense10 (Dense)   (None, 512)          262656      covertype_dec_add3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense11 (Dense)   (None, 512)          262656      covertype_dec_dense10[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense12 (Dense)   (None, 512)          262656      covertype_dec_dense11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add4 (Add)        (None, 512)          0           covertype_dec_dense10[0][0]      \n",
      "                                                                 covertype_dec_dense12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense13 (Dense)   (None, 512)          262656      covertype_dec_add4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense14 (Dense)   (None, 512)          262656      covertype_dec_dense13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense15 (Dense)   (None, 512)          262656      covertype_dec_dense14[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add5 (Add)        (None, 512)          0           covertype_dec_dense13[0][0]      \n",
      "                                                                 covertype_dec_dense15[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense16 (Dense)   (None, 512)          262656      covertype_dec_add5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense17 (Dense)   (None, 512)          262656      covertype_dec_dense16[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense18 (Dense)   (None, 512)          262656      covertype_dec_dense17[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add6 (Add)        (None, 512)          0           covertype_dec_dense16[0][0]      \n",
      "                                                                 covertype_dec_dense18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense19 (Dense)   (None, 512)          262656      covertype_dec_add6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense20 (Dense)   (None, 512)          262656      covertype_dec_dense19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense21 (Dense)   (None, 512)          262656      covertype_dec_dense20[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add7 (Add)        (None, 512)          0           covertype_dec_dense19[0][0]      \n",
      "                                                                 covertype_dec_dense21[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense22 (Dense)   (None, 512)          262656      covertype_dec_add7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense23 (Dense)   (None, 512)          262656      covertype_dec_dense22[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense24 (Dense)   (None, 512)          262656      covertype_dec_dense23[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add8 (Add)        (None, 512)          0           covertype_dec_dense22[0][0]      \n",
      "                                                                 covertype_dec_dense24[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense25 (Dense)   (None, 512)          262656      covertype_dec_add8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense26 (Dense)   (None, 512)          262656      covertype_dec_dense25[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense27 (Dense)   (None, 512)          262656      covertype_dec_dense26[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add9 (Add)        (None, 512)          0           covertype_dec_dense25[0][0]      \n",
      "                                                                 covertype_dec_dense27[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense28 (Dense)   (None, 512)          262656      covertype_dec_add9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense29 (Dense)   (None, 512)          262656      covertype_dec_dense28[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense30 (Dense)   (None, 512)          262656      covertype_dec_dense29[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add10 (Add)       (None, 512)          0           covertype_dec_dense28[0][0]      \n",
      "                                                                 covertype_dec_dense30[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense31 (Dense)   (None, 512)          262656      covertype_dec_add10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense32 (Dense)   (None, 512)          262656      covertype_dec_dense31[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense33 (Dense)   (None, 512)          262656      covertype_dec_dense32[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add11 (Add)       (None, 512)          0           covertype_dec_dense31[0][0]      \n",
      "                                                                 covertype_dec_dense33[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense34 (Dense)   (None, 512)          262656      covertype_dec_add11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense35 (Dense)   (None, 512)          262656      covertype_dec_dense34[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense36 (Dense)   (None, 512)          262656      covertype_dec_dense35[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add12 (Add)       (None, 512)          0           covertype_dec_dense34[0][0]      \n",
      "                                                                 covertype_dec_dense36[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense37 (Dense)   (None, 512)          262656      covertype_dec_add12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense38 (Dense)   (None, 512)          262656      covertype_dec_dense37[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense39 (Dense)   (None, 512)          262656      covertype_dec_dense38[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add13 (Add)       (None, 512)          0           covertype_dec_dense37[0][0]      \n",
      "                                                                 covertype_dec_dense39[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense40 (Dense)   (None, 512)          262656      covertype_dec_add13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense41 (Dense)   (None, 512)          262656      covertype_dec_dense40[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense42 (Dense)   (None, 512)          262656      covertype_dec_dense41[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add14 (Add)       (None, 512)          0           covertype_dec_dense40[0][0]      \n",
      "                                                                 covertype_dec_dense42[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense43 (Dense)   (None, 512)          262656      covertype_dec_add14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense44 (Dense)   (None, 512)          262656      covertype_dec_dense43[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_dense45 (Dense)   (None, 512)          262656      covertype_dec_dense44[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_dec_add15 (Add)       (None, 512)          0           covertype_dec_dense43[0][0]      \n",
      "                                                                 covertype_dec_dense45[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "covertype_cls (Functional)      (None, 7)            20487       covertype_z[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "covertype_reconstruction (Dense (None, 54)           27702       covertype_dec_add15[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 23,494,253\n",
      "Trainable params: 23,494,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainable_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "5F-mTtjB5WrP"
   },
   "outputs": [],
   "source": [
    "nn_fname = 'covertype_united.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "CkUNeVkB4ysG"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=ES_PATIENCE,\n",
    "        mode=\"min\",\n",
    "        restore_best_weights=False\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=nn_fname,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.33,\n",
    "        patience=2,\n",
    "        verbose=True,\n",
    "        mode=\"min\",\n",
    "        monitor=\"loss\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "P5yO4Kj-5n_g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "513/513 [==============================] - 311s 498ms/step - loss: 1.2955 - covertype_cls_loss: 0.9192 - covertype_reconstruction_loss: 0.1927 - covertype_cls_categorical_accuracy: 0.7669 - val_loss: 1.2725 - val_covertype_cls_loss: 0.9572 - val_covertype_reconstruction_loss: 0.1683 - val_covertype_cls_categorical_accuracy: 0.7440\n",
      "Epoch 2/2000\n",
      "513/513 [==============================] - 252s 491ms/step - loss: 0.9687 - covertype_cls_loss: 0.7288 - covertype_reconstruction_loss: 0.1189 - covertype_cls_categorical_accuracy: 0.8720 - val_loss: 1.0915 - val_covertype_cls_loss: 0.8341 - val_covertype_reconstruction_loss: 0.1401 - val_covertype_cls_categorical_accuracy: 0.8085\n",
      "Epoch 3/2000\n",
      "513/513 [==============================] - 252s 492ms/step - loss: 0.9813 - covertype_cls_loss: 0.7271 - covertype_reconstruction_loss: 0.1304 - covertype_cls_categorical_accuracy: 0.8743 - val_loss: 1.1664 - val_covertype_cls_loss: 0.8758 - val_covertype_reconstruction_loss: 0.1605 - val_covertype_cls_categorical_accuracy: 0.7922\n",
      "Epoch 4/2000\n",
      "513/513 [==============================] - 251s 490ms/step - loss: 1.1307 - covertype_cls_loss: 0.8417 - covertype_reconstruction_loss: 0.1545 - covertype_cls_categorical_accuracy: 0.8156 - val_loss: 1.6224 - val_covertype_cls_loss: 1.2130 - val_covertype_reconstruction_loss: 0.2385 - val_covertype_cls_categorical_accuracy: 0.5951\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00033000001567415896.\n",
      "Epoch 5/2000\n",
      "513/513 [==============================] - 256s 498ms/step - loss: 1.2162 - covertype_cls_loss: 0.8839 - covertype_reconstruction_loss: 0.1919 - covertype_cls_categorical_accuracy: 0.7733 - val_loss: 1.1574 - val_covertype_cls_loss: 0.8582 - val_covertype_reconstruction_loss: 0.1740 - val_covertype_cls_categorical_accuracy: 0.7968\n",
      "Epoch 6/2000\n",
      "513/513 [==============================] - 254s 496ms/step - loss: 1.0464 - covertype_cls_loss: 0.7558 - covertype_reconstruction_loss: 0.1678 - covertype_cls_categorical_accuracy: 0.8556 - val_loss: 1.0497 - val_covertype_cls_loss: 0.8023 - val_covertype_reconstruction_loss: 0.1391 - val_covertype_cls_categorical_accuracy: 0.8356\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010890000325161964.\n",
      "Epoch 7/2000\n",
      "513/513 [==============================] - 256s 500ms/step - loss: 0.8733 - covertype_cls_loss: 0.6690 - covertype_reconstruction_loss: 0.1108 - covertype_cls_categorical_accuracy: 0.9026 - val_loss: 0.9728 - val_covertype_cls_loss: 0.7543 - val_covertype_reconstruction_loss: 0.1197 - val_covertype_cls_categorical_accuracy: 0.8610\n",
      "Epoch 8/2000\n",
      "513/513 [==============================] - 249s 485ms/step - loss: 0.8064 - covertype_cls_loss: 0.6254 - covertype_reconstruction_loss: 0.0956 - covertype_cls_categorical_accuracy: 0.9243 - val_loss: 0.9092 - val_covertype_cls_loss: 0.7131 - val_covertype_reconstruction_loss: 0.1048 - val_covertype_cls_categorical_accuracy: 0.8792\n",
      "Epoch 9/2000\n",
      "513/513 [==============================] - 241s 469ms/step - loss: 0.7794 - covertype_cls_loss: 0.6127 - covertype_reconstruction_loss: 0.0866 - covertype_cls_categorical_accuracy: 0.9291 - val_loss: 0.9009 - val_covertype_cls_loss: 0.7165 - val_covertype_reconstruction_loss: 0.0979 - val_covertype_cls_categorical_accuracy: 0.8782\n",
      "Epoch 10/2000\n",
      "513/513 [==============================] - 230s 447ms/step - loss: 0.7429 - covertype_cls_loss: 0.5904 - covertype_reconstruction_loss: 0.0768 - covertype_cls_categorical_accuracy: 0.9389 - val_loss: 0.8666 - val_covertype_cls_loss: 0.6940 - val_covertype_reconstruction_loss: 0.0898 - val_covertype_cls_categorical_accuracy: 0.8901\n",
      "Epoch 11/2000\n",
      "513/513 [==============================] - 237s 463ms/step - loss: 0.7315 - covertype_cls_loss: 0.5856 - covertype_reconstruction_loss: 0.0726 - covertype_cls_categorical_accuracy: 0.9415 - val_loss: 0.8874 - val_covertype_cls_loss: 0.6983 - val_covertype_reconstruction_loss: 0.1001 - val_covertype_cls_categorical_accuracy: 0.8876\n",
      "Epoch 12/2000\n",
      " 27/513 [>.............................] - ETA: 3:49 - loss: 0.7286 - covertype_cls_loss: 0.5826 - covertype_reconstruction_loss: 0.0721 - covertype_cls_categorical_accuracy: 0.9408"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14864/595442426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_history = trainable_nn.fit(trainset_gen, validation_data=validset_gen,\n\u001b[0;32m      2\u001b[0m                                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_TRAINING_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                                  verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\env_for_tf2\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 _r=1):\n\u001b[0;32m   1177\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\env_for_tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\env_for_tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\env_for_tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\env_for_tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\env_for_tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\env_for_tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history = trainable_nn.fit(trainset_gen, validation_data=validset_gen,\n",
    "                                 epochs=MAX_TRAINING_EPOCHS, callbacks=callbacks,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg2TlJsd6B8Q"
   },
   "outputs": [],
   "source": [
    "trainable_nn.load_weights(nn_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZxVYvkm6diP"
   },
   "outputs": [],
   "source": [
    "show_training_process(history=model_history, metric_name='loss',\n",
    "                      figure_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMNeqB866o7e"
   },
   "outputs": [],
   "source": [
    "show_training_process(history=model_history, metric_name='covertype_cls_loss',\n",
    "                      figure_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kd3SKKEZ6kgl"
   },
   "outputs": [],
   "source": [
    "show_training_process(history=model_history,\n",
    "                      metric_name='covertype_cls_categorical_accuracy',\n",
    "                      figure_id=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNMlYkPu7Ic_"
   },
   "outputs": [],
   "source": [
    "del trainset_gen, validset_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igS2mcBB7Kzd"
   },
   "outputs": [],
   "source": [
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36JzbsBtHGdv"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_probas = predict_proba(\n",
    "    X=X_valid, encoder=encoding_nn, classifier=classification_nn,\n",
    "    n_samples=1, batch_size=MINIBATCH_SIZE_FOR_INFERENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_valid, y_pred=np.argmax(valid_probas, axis=1),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGYcDvS97-jv"
   },
   "outputs": [],
   "source": [
    "test_probas = predict_proba(\n",
    "    X=X_test, encoder=encoding_nn, classifier=classification_nn,\n",
    "    n_samples=1, batch_size=MINIBATCH_SIZE_FOR_INFERENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reZKYYG28A3F"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=np.argmax(test_probas, axis=1),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas = predict_proba(\n",
    "    X=X_test, encoder=encoding_nn, classifier=classification_nn,\n",
    "    n_samples=10, batch_size=MINIBATCH_SIZE_FOR_INFERENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=np.argmax(test_probas, axis=1),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probas = predict_proba(\n",
    "    X=X_test, encoder=encoding_nn, classifier=classification_nn,\n",
    "    n_samples=100, batch_size=MINIBATCH_SIZE_FOR_INFERENCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=np.argmax(test_probas, axis=1),\n",
    "                            digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classes(\n",
    "    features=reduce_dimensions_of_data(X_test),\n",
    "    targets=y_test,\n",
    "    class_colors=COLORS_OF_CLASSES,\n",
    "    title='source inputs',\n",
    "    figure_id=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classes(\n",
    "    features=reduce_dimensions_of_data(\n",
    "        reconstruct_inputs(\n",
    "            X=X_test,\n",
    "            vae=trainable_nn,\n",
    "            batch_size=MINIBATCH_SIZE_FOR_INFERENCE\n",
    "        )\n",
    "    ),\n",
    "    targets=y_test,\n",
    "    class_colors=COLORS_OF_CLASSES,\n",
    "    title='reconstructed inputs',\n",
    "    figure_id=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_classes(\n",
    "    features=reduce_dimensions_of_data(\n",
    "        calculate_projections(\n",
    "            X=X_test,\n",
    "            encoder=encoding_nn,\n",
    "            n_samples=1,\n",
    "            batch_size=MINIBATCH_SIZE_FOR_INFERENCE\n",
    "        )[0]\n",
    "    ),\n",
    "    targets=y_test,\n",
    "    class_colors=COLORS_OF_CLASSES,\n",
    "    title='latent variables',\n",
    "    figure_id=7\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_automl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
